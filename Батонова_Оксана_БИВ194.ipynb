{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\n\ndef get_device():\n    # Если в системе есть GPU ...\n    if torch.cuda.is_available():\n        # Тогда говорим PyTorch использовать GPU.\n        device = torch.device(\"cuda\")\n        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n        print('We will use the GPU:', torch.cuda.get_device_name(0))\n    # Если нет GPU, то считаем на обычном процессоре ...\n    else:\n        print('No GPU available, using the CPU instead.')\n        device = torch.device(\"cpu\")\n    return device\n\n\ndevice = get_device()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-03T20:12:07.203618Z","iopub.execute_input":"2022-12-03T20:12:07.205121Z","iopub.status.idle":"2022-12-03T20:12:09.379688Z","shell.execute_reply.started":"2022-12-03T20:12:07.205076Z","shell.execute_reply":"2022-12-03T20:12:09.378199Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"No GPU available, using the CPU instead.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/miem-hse-ais-2022-lab-03/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-03T20:12:09.381111Z","iopub.execute_input":"2022-12-03T20:12:09.381884Z","iopub.status.idle":"2022-12-03T20:12:10.396508Z","shell.execute_reply.started":"2022-12-03T20:12:09.381843Z","shell.execute_reply":"2022-12-03T20:12:10.395028Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   review_id  movie_id                                               text  \\\n0          0         0  \\nСтарая поговорка гласит: «Лучшие рассказы — ...   \n1          1         0  \\nСамое сильное кино начала этого года, или ко...   \n2          2         0  \\nДушевно. Когда противоположности встречаются...   \n3          3         0  \\nОб этом фильме я вообще ничего не знал, но н...   \n4          4         0  \\nКак правило, история людей, которые прикован...   \n\n  label  \n0  Good  \n1  Good  \n2  Good  \n3  Good  \n4  Good  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>movie_id</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>\\nСтарая поговорка гласит: «Лучшие рассказы — ...</td>\n      <td>Good</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>\\nСамое сильное кино начала этого года, или ко...</td>\n      <td>Good</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>\\nДушевно. Когда противоположности встречаются...</td>\n      <td>Good</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>\\nОб этом фильме я вообще ничего не знал, но н...</td>\n      <td>Good</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>\\nКак правило, история людей, которые прикован...</td>\n      <td>Good</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom imblearn.over_sampling import RandomOverSampler\ndf = pd.read_csv('/kaggle/input/miem-hse-ais-2022-lab-03/train.csv', header=None, names=['review_id', 'movie_id', 'sentences', 'label'])\nOverSampler = RandomOverSampler()\nfor i in range(df.shape[0]):\n        if (df.loc[i, 'label'] =='Good'):\n            df.loc[i, 'label'] = '1'\n        else:\n            df.loc[i, 'label'] = '0'\nsentences, labels = OverSampler.fit_resample(df['sentences'].values.reshape(-1, 1), df['label'].values)\nsentences =  sentences.reshape(-1)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-03T20:12:41.856905Z","iopub.execute_input":"2022-12-03T20:12:41.857467Z","iopub.status.idle":"2022-12-03T20:12:45.755178Z","shell.execute_reply.started":"2022-12-03T20:12:41.857426Z","shell.execute_reply":"2022-12-03T20:12:45.753696Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer\nprint('Loading BERT tokenizer...')\ntokenizer_path = 'cointegrated/rubert-tiny'\ntokenizer = BertTokenizer.from_pretrained(tokenizer_path, truncation=True, max_length=256)\n\nsentence_number = 1\n# Напечатать оригинальное предложение.\nprint('Original:', sentences[sentence_number])\n# Напечатать предложение разбитое на отдельные токены из словаря.\nprint('Tokenized: ', tokenizer.tokenize(sentences[sentence_number]))\n# Напечатать предложение разбитое на номера токенов в словаре.\nprint('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[sentence_number])))","metadata":{"execution":{"iopub.status.busy":"2022-12-03T20:13:01.502875Z","iopub.execute_input":"2022-12-03T20:13:01.503338Z","iopub.status.idle":"2022-12-03T20:13:03.761919Z","shell.execute_reply.started":"2022-12-03T20:13:01.503300Z","shell.execute_reply":"2022-12-03T20:13:03.760352Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Loading BERT tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/235k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1ff2317a05848dda5550ea3c2ab43af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b05917a2ed7448e5b4c94a2054752fe4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/341 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca24b75e44c240aeaf55654ccfc1fb1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/632 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d424f7f80e99425182cfdb6041b46733"}},"metadata":{}},{"name":"stdout","text":"Original: \nСтарая поговорка гласит: «Лучшие рассказы — это рассказы написанные самой жизнью». Режиссёрскому дуэту Оливье Накаша и Эрика Толедано удалось правильно рассказать трагикомедию основанную на реальной истории бедного молодого араба из французского гетто и парализованного бизнесмена, которых судьба связала неожиданной дружбой, несмотря на то, что в реальности их ничего не связывает, будь то социальный статус, или взгляды на понимание жизни. \n\nОчаровательная трагикомедия «Неприкасаемые» прежде всего имеет сердце и ум, полностью свободный от штампов о проявлении сострадания к инвалидам и прочим недееспособным людям. Фильм правильно позволяет им, в лице Филиппа, ощущать себя такими же практически полноценными людьми, как и все остальные, передавая всё это в юмористической форме, часто граничащей с обезоруживающей откровенностью. А происходит это на экране благодаря прежде всего увлекательной атмосфере, которую создаёт отличный дуэт Омара Сая, кажется имеющего в кармане свежую шутку и Франсуа Клюзе, лишь через мимику и голос мастерски делающего этот фильм успешным. Кроме этого фильм также затрагивает мимоходом и другие темы, которые по-прежнему вызывают много вопросов во французском обществе, будь то безработица среди эмигрантов, или детская преступность, в промежутках между которыми имея возможность ещё и покритиковать современное искусство, которое в 90% своих случаев граничит с простой детской мазней, но будучи высоко оценённым критиками выдаётся за нечто гениальное.\n\nСоздав, в конечном итоге, жизнеутверждающий, остроумный, веселый и обаятельный взрыв смеси драмы и комедии в наиболее эффективных пропорциях, «Неприкасаемые» стали практически идеальным фильмом для любой аудитории и уж точно одной из лучших французских лент 2011 года!\nTokenized:  ['Стара', '##я', 'по', '##говор', '##ка', 'гл', '##ас', '##ит', ':', '«', 'Л', '##учшие', 'р', '##ассказы', '[UNK]', 'это', 'р', '##ассказы', 'на', '##писан', '##ные', 'самой', 'жизнь', '##ю', '»', '.', 'Режиссёр', '##скому', 'ду', '##эт', '##у', 'Ол', '##ив', '##ье', 'На', '##ка', '##ша', 'и', 'Э', '##рика', 'То', '##ле', '##дано', 'удалось', 'правил', '##ьно', 'р', '##ассказ', '##ать', 'т', '##раг', '##иком', '##еди', '##ю', 'основан', '##ную', 'на', 'р', '##е', '##альной', 'истории', 'б', '##едно', '##го', 'молодого', 'араб', '##а', 'из', 'французского', 'ге', '##тто', 'и', 'пара', '##ли', '##зован', '##ного', 'бизнес', '##мена', ',', 'которых', 'суд', '##ьба', 'св', '##яз', '##ала', 'не', '##о', '##жи', '##дан', '##ной', 'др', '##у', '##ж', '##бой', ',', 'несмотря', 'на', 'то', ',', 'что', 'в', 'р', '##е', '##ально', '##сти', 'их', 'ничего', 'не', 'св', '##яз', '##ывает', ',', 'будь', 'то', 'со', '##циальный', 'статус', ',', 'или', 'в', '##з', '##гляд', '##ы', 'на', 'по', '##нима', '##ние', 'жизни', '.', 'О', '##чар', '##ова', '##тельная', 'т', '##раг', '##иком', '##еди', '##я', '«', 'Не', '##пр', '##ика', '##са', '##емые', '»', 'прежде', 'всего', 'имеет', 'се', '##рдце', 'и', 'ум', ',', 'полностью', 'св', '##об', '##од', '##ный', 'от', 'ш', '##там', '##пов', 'о', 'про', '##яв', '##лении', 'сост', '##рада', '##ния', 'к', 'ин', '##вали', '##дам', 'и', 'про', '##чим', 'не', '##де', '##ес', '##пособ', '##ным', 'людям', '.', 'Фильм', 'правил', '##ьно', 'позволяет', 'им', ',', 'в', 'лице', 'Филипп', '##а', ',', 'о', '##щу', '##щать', 'себя', 'такими', 'же', 'практически', 'пол', '##но', '##цен', '##ными', 'людьми', ',', 'как', 'и', 'все', 'остальные', ',', 'перед', '##ава', '##я', 'всё', 'это', 'в', 'юм', '##ори', '##сти', '##ческой', 'форме', ',', 'часто', 'гр', '##ани', '##ча', '##щей', 'с', 'обе', '##зор', '##у', '##жив', '##аю', '##щей', 'от', '##к', '##ров', '##енно', '##стью', '.', 'А', 'происходит', 'это', 'на', 'э', '##к', '##ране', 'благодаря', 'прежде', 'всего', 'у', '##в', '##лек', '##атель', '##ной', 'ат', '##мос', '##фер', '##е', ',', 'которую', 'со', '##зда', '##ёт', 'от', '##ли', '##чный', 'ду', '##эт', 'О', '##мар', '##а', 'Са', '##я', ',', 'каже', '##тся', 'име', '##ющего', 'в', 'кар', '##ман', '##е', 'све', '##жу', '##ю', 'ш', '##ут', '##ку', 'и', 'Франсуа', 'К', '##лю', '##зе', ',', 'лишь', 'через', 'ми', '##мик', '##у', 'и', 'голос', 'мастер', '##ски', 'дела', '##ющего', 'этот', 'фильм', 'у', '##с', '##пе', '##ш', '##ным', '.', 'Кроме', 'этого', 'фильм', 'также', 'за', '##тра', '##ги', '##вает', 'ми', '##мо', '##ходом', 'и', 'другие', 'тем', '##ы', ',', 'которые', 'по', '-', 'пре', '##жнем', '##у', 'вы', '##зы', '##вают', 'много', 'вопрос', '##ов', 'во', 'француз', '##ском', 'об', '##ществе', ',', 'будь', 'то', 'без', '##ра', '##бо', '##ти', '##ца', 'среди', 'эми', '##гра', '##нтов', ',', 'или', 'де', '##тская', 'пре', '##ступ', '##ность', ',', 'в', 'про', '##ме', '##жу', '##тка', '##х', 'между', 'которыми', 'име', '##я', 'возможность', 'ещё', 'и', 'по', '##крити', '##кова', '##ть', 'сов', '##рем', '##енное', 'искусство', ',', 'которое', 'в', '90', '%', 'своих', 'случаев', 'гр', '##ани', '##чит', 'с', 'просто', '##й', 'де', '##тской', 'ма', '##з', '##ней', ',', 'но', 'будучи', 'вы', '##сок', '##о', 'о', '##цен', '##ённым', 'критик', '##ами', 'вы', '##даётся', 'за', 'не', '##ч', '##то', 'ге', '##ни', '##альное', '.', 'Со', '##зда', '##в', ',', 'в', 'кон', '##ечно', '##м', 'итоге', ',', 'ж', '##из', '##не', '##ут', '##вер', '##жда', '##ющий', ',', 'ос', '##тро', '##ум', '##ный', ',', 'в', '##есе', '##лый', 'и', 'оба', '##ят', '##ель', '##ный', 'в', '##з', '##рыв', 'см', '##еси', 'др', '##амы', 'и', 'коме', '##дии', 'в', 'наиболее', 'э', '##ффект', '##ивных', 'про', '##пор', '##циях', ',', '«', 'Не', '##пр', '##ика', '##са', '##емые', '»', 'стали', 'практически', 'и', '##де', '##альным', 'фильм', '##ом', 'для', 'любой', 'а', '##уди', '##тори', '##и', 'и', 'у', '##ж', 'точно', 'одной', 'из', 'лучших', 'француз', '##ских', 'ле', '##нт', '2011', 'года', '!']\nToken IDs:  [21522, 776, 705, 11316, 872, 17189, 4992, 3825, 30, 105, 291, 26681, 328, 24554, 1, 2389, 328, 24554, 548, 11853, 1308, 14382, 8603, 920, 117, 18, 23132, 8105, 1560, 9287, 644, 11450, 4831, 5976, 1041, 872, 2506, 320, 309, 18811, 9961, 1736, 24221, 10441, 22255, 7646, 328, 26512, 4963, 330, 23369, 29342, 24274, 920, 11754, 2233, 548, 328, 626, 12065, 3869, 313, 23368, 1172, 27790, 17033, 603, 778, 24106, 19783, 27174, 320, 20379, 1044, 18274, 1211, 20739, 7590, 16, 3671, 11783, 15957, 12105, 22850, 3683, 769, 721, 3419, 3526, 1229, 4154, 644, 1845, 10970, 16, 15096, 548, 1619, 16, 1046, 314, 328, 626, 17228, 1948, 1870, 20125, 769, 12105, 22850, 11791, 16, 12261, 1619, 1154, 25302, 8146, 16, 1109, 314, 1556, 13386, 700, 548, 705, 26909, 2677, 4482, 18, 294, 12837, 1841, 17288, 330, 23369, 29342, 24274, 776, 105, 6226, 11401, 3544, 1839, 20062, 117, 16860, 4983, 5287, 689, 25888, 320, 12685, 16, 9297, 12105, 10658, 4197, 1241, 733, 336, 15585, 13822, 326, 2225, 16196, 10516, 25742, 16451, 1988, 322, 8781, 4309, 13178, 320, 2225, 20463, 769, 1987, 4608, 26837, 1635, 27000, 18, 18013, 22255, 7646, 14736, 2558, 16, 314, 22276, 27108, 603, 16, 326, 15910, 23333, 4788, 17479, 1712, 11781, 7283, 948, 25007, 3092, 21667, 16, 1150, 320, 2749, 24026, 16, 5189, 8673, 776, 7757, 2389, 314, 6438, 9790, 1948, 4348, 14812, 16, 5166, 17348, 7883, 2411, 9634, 329, 21010, 15349, 644, 16527, 28070, 9634, 733, 865, 3801, 17594, 11309, 18, 280, 10833, 2389, 548, 341, 865, 11588, 10871, 16860, 4983, 331, 887, 9573, 27942, 1229, 21642, 27804, 14788, 626, 16, 9871, 1154, 14338, 4459, 733, 1044, 8034, 1560, 9287, 294, 14063, 603, 17357, 776, 16, 26488, 6868, 7578, 9503, 314, 8573, 3125, 626, 7976, 8700, 920, 336, 5619, 1305, 320, 25748, 290, 6258, 3798, 16, 5943, 2277, 11951, 26768, 644, 320, 27538, 18442, 1468, 7843, 9503, 5557, 5880, 331, 866, 5677, 1276, 1635, 18, 7431, 3136, 5880, 1479, 650, 9412, 2987, 12230, 11951, 5709, 22434, 320, 5685, 5624, 700, 16, 2938, 705, 17, 12383, 26428, 644, 26629, 5892, 12729, 4064, 17959, 811, 815, 27040, 1930, 2514, 25843, 16, 12261, 1619, 2399, 1232, 9422, 1156, 1483, 4538, 23898, 20816, 13240, 16, 1109, 1395, 25280, 12383, 19408, 4420, 16, 314, 2225, 3277, 8700, 8533, 753, 2504, 25324, 7578, 776, 11195, 3952, 320, 705, 22794, 5812, 1348, 27180, 17010, 18671, 21651, 16, 8284, 314, 1132, 9, 6041, 27926, 17348, 7883, 21062, 329, 9922, 775, 1395, 15790, 26941, 1556, 4371, 16, 1363, 17872, 26629, 14354, 721, 326, 25007, 24517, 29521, 1854, 26629, 27850, 650, 769, 1669, 1026, 19783, 958, 18497, 18, 11847, 14338, 887, 16, 314, 10578, 22142, 656, 14373, 16, 318, 12666, 987, 5619, 10377, 12321, 6050, 16, 24485, 19173, 5895, 1241, 16, 314, 16462, 15243, 320, 16691, 2434, 4550, 1241, 314, 1556, 22791, 4159, 16248, 4154, 23903, 320, 19952, 10528, 314, 8379, 341, 28588, 22685, 2225, 13568, 23599, 16, 105, 6226, 11401, 3544, 1839, 20062, 117, 4596, 11781, 320, 1987, 28170, 5880, 761, 871, 21943, 312, 9446, 18324, 613, 320, 331, 1845, 17325, 6039, 778, 15439, 27040, 2083, 26335, 4406, 583, 735, 5]\n","output_type":"stream"}]},{"cell_type":"code","source":"max_len = 0\n# Считаем какой максимальный размер имеет предложение разбитое на токены и разбавленное спец. токенами.\nfor sent in sentences:\n    # Токенизируем текст и добавляем `[CLS]` и `[SEP]` токены.\n    input_ids = tokenizer.encode(sent, add_special_tokens=True, truncation=True, max_length=64)\n    # Обновляем максимум.\n    max_len = max(max_len, len(input_ids))\nprint('Max sentence length: ', max_len)","metadata":{"execution":{"iopub.status.busy":"2022-12-03T20:13:07.122924Z","iopub.execute_input":"2022-12-03T20:13:07.123534Z","iopub.status.idle":"2022-12-03T20:18:30.788910Z","shell.execute_reply.started":"2022-12-03T20:13:07.123482Z","shell.execute_reply":"2022-12-03T20:18:30.787151Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Max sentence length:  64\n","output_type":"stream"}]},{"cell_type":"code","source":"input_ids, attention_masks = [], []\n\n# Для всех предложений...\nfor sent in sentences:\n    encoded_dict = tokenizer.encode_plus(\n        sent,  # Текст для токенизации.\n        add_special_tokens=True,  # Добавляем '[CLS]' и '[SEP]'\n        max_length=128,  # Дополняем [PAD] или обрезаем текст до 64 токенов.\n        padding='max_length',#pad_to_max_length=True,\n        return_attention_mask=True,  # Возвращаем также attn. masks.\n        return_tensors='pt',  # Возвращаем в виде тензоров pytorch.\n        truncation=True,\n    )\n\n    # Добавляем токенизированное предложение в список\n    input_ids.append(encoded_dict['input_ids'])\n    # И добавляем attention mask в список\n    attention_masks.append(encoded_dict['attention_mask'])\n\n# Конвертируем списки в полноценные тензоры Pytorch.\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)\nlabels = torch.tensor( pd.to_numeric(labels))\n# Печатаем предложение с номером 1, его токены (теперь в виде номеров в словаре) и.т.д.\nprint('Original: ', sentences[1])\nprint('Token IDs:', input_ids[1])\nprint('Attention masks:', attention_masks[1])\nprint('Labels:', labels[1])","metadata":{"execution":{"iopub.status.busy":"2022-12-03T20:18:30.791424Z","iopub.execute_input":"2022-12-03T20:18:30.791943Z","iopub.status.idle":"2022-12-03T20:21:45.477628Z","shell.execute_reply.started":"2022-12-03T20:18:30.791891Z","shell.execute_reply":"2022-12-03T20:21:45.475234Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3057563878.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Возвращаем также attn. masks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Возвращаем в виде тензоров pytorch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2604\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2605\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2606\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2607\u001b[0m         )\n\u001b[1;32m   2608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m             )\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;31m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;31m# If the token is part of the never_split set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_accents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_strip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_split_on_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhitespace_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_run_split_on_punc\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0m_is_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0mstart_new_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, random_split\n\n# Объединяем все тренировочные данные в один TensorDataset.\ndataset = TensorDataset(input_ids, attention_masks, labels)\n\n# Делаем разделение случайное разбиение 90% - тренировка 10% - валидация.\n\n# Считаем число данных для тренировки и для валидации.\ntrain_size = int(0.9 * len(dataset))\nval_size = len(dataset) - train_size\n\n# Разбиваем датасет с учетом посчитанного количества.\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nprint('{:>5,} training samples'.format(train_size))\nprint('{:>5,} validation samples'.format(val_size))","metadata":{"execution":{"iopub.status.busy":"2022-12-03T20:21:45.478961Z","iopub.status.idle":"2022-12-03T20:21:45.479444Z","shell.execute_reply.started":"2022-12-03T20:21:45.479213Z","shell.execute_reply":"2022-12-03T20:21:45.479233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n\n# DataLoader должен знать размер батча для тренировки мы задаем его здесь.\n# Размер батча – это сколько текстов будет подаваться на сеть для вычисления градиентов\n# Авторы BERT предлагают ставить его 16 или 32. \nbatch_size = 64\n\n# Создаем отдельные DataLoaders для наших тренировочного и валидационного наборов\n\n# Для тренировки мы берем тексты в случайном порядке.\ntrain_dataloader = DataLoader(\n        train_dataset,  # Тренировочный набор данных.\n        sampler = RandomSampler(train_dataset), # Выбираем батчи случайно\n        batch_size = batch_size # Тренируем с таким размером батча.\n)\n\n# Для валидации порядок не важен, поэтому зачитываем их последовательно.\nvalidation_dataloader = DataLoader(\n        val_dataset, # Валидационный набор данных.\n        sampler = SequentialSampler(val_dataset), # Выбираем батчи последовательно.\n        batch_size = batch_size # Считаем качество модели с таким размером батча.\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, AdamW, BertConfig\n\n# Загружаем BertForSequenceClassification. Это предобученная модель BERT с одиночным полносвязным слоем для классификации\nmodel = BertForSequenceClassification.from_pretrained(\n    tokenizer_path, # Используем 12-слойную модель BERT, со словарем без регистра.\n    num_labels = 2, # Количество выходных слоёв – 2 для бинарной классификации. Можно увеличить для мультиклассовой классификации.\n    output_attentions = False, # Будет ли модель возвращать веса для attention-слоёв. В нашем случае нет.\n    output_hidden_states = False, # Будет ли модель возвращать состояние всех скрытых слоёв. В нашем случае нет.\n)\n\n# Здесь мы говорим PyTorch что хотим тренировать модель на GPU.\nif torch.cuda.is_available():\n    model.cuda()\n\n# Получаем все параметры модели как список кортежей и выводим сводную информацию по модели.\nparams = list(model.named_parameters())\nprint('The BERT model has {:} different named parameters.\\n'.format(len(params)))\nprint('==== Embedding Layer ====\\n')\nfor p in params[0:5]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== First Transformer ====\\n')\nfor p in params[5:21]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== Output Layer ====\\n')\nfor p in params[-4:]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW (model.parameters(),\n    lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n    eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n)\n\nfrom transformers import get_linear_schedule_with_warmup\n\n# Количество эпох для тренировки. Авторы BERT рекомендуют от 2 до 4.\n# Мы выбираем 4, но увидим позже, что это приводит к оверфиту на тренировочные данные.\nepochs = 2\n\n# Общее число шагов тренировки равно [количество батчей] x [число эпох].\ntotal_steps = len(train_dataloader) * epochs\n\n# Создаем планировщик learning rate (LR). LR будет плавно уменьшаться в процессе тренировки\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps = 0, # Default value in run_glue.py\n                                            num_training_steps = total_steps)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Функция для расчёта точности. Сравниваются предсказания и реальная разметка к данным\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n\n\nimport time\nimport datetime\nimport random \n\n# На вход время в секундах и возвращается строка в формате hh:mm:ss\ndef format_time(elapsed):\n    # Округляем до ближайшей секунды.\n    elapsed_rounded = int(round((elapsed)))\n\n    # Форматируем как hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_step(device, model, train_dataloader, optimizer, scheduler):\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    t0 = time.time()\n    total_train_loss = 0\n    # Переводим модель в режим тренировки.\n    model.train()\n\n    # Для каждого батча из тренировочных данных...\n    for step, batch in enumerate(train_dataloader):\n        if step % 40 == 0 and not step == 0:\n            elapsed = format_time(time.time() - t0)\n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n\n        # Извлекаем все компоненты из полученного батча\n        b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n        # Очищаем все ранее посчитанные градиенты (это важно)\n        model.zero_grad()\n        # Выполняем прямой проход по данным\n        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n        loss = outputs.loss\n        logits = outputs.logits\n        # Накапливаем тренировочную функцию потерь по всем батчам        \n        total_train_loss += loss.item()\n        # Выполняем обратное распространение ошибки что бы посчитать градиенты.\n        loss.backward()\n        # Ограничиваем максимальный размер градиента до 1.0. Это позволяет избежать проблемы \"exploding gradients\".\n        #############torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        # Обновляем параметры модели используя рассчитанные градиенты с помощью выбранного оптимизатора и текущего learning rate.\n        optimizer.step()\n        # Обновляем learning rate.\n        scheduler.step()\n\n    # Считаем среднее значение функции потерь по всем батчам.\n    avg_train_loss = total_train_loss / len(train_dataloader)\n    # Сохраняем время тренировки одной эпохи.\n    training_time = format_time(time.time() - t0)\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Training epcoh took: {:}\".format(training_time))\n    return avg_train_loss, training_time","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validation_step(device, model, validation_dataloader):\n    print(\"Running Validation...\")\n    t0 = time.time()\n    # Переводим модель в режим evaluation – некоторые слои, например dropout ведут себя по другому.\n    model.eval()\n\n    # Переменные для подсчёта функции потерь и точности\n    total_eval_accuracy = 0\n    total_eval_loss = 0\n    # Прогоняем все данные из валидации\n    for batch in validation_dataloader:\n        # Извлекаем все компоненты из полученного батча.\n        b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n\n        # Говорим pytorch что нам не нужен вычислительный граф для подсчёта градиентов (всё будет работать намного быстрее)\n        with torch.no_grad():\n            # Прямой проход по нейронной сети и получение выходных значений.\n            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n            loss = outputs.loss\n            logits = outputs.logits\n\n        # Накапливаем значение функции потерь для валидации.\n        total_eval_loss += loss.item()\n\n        # Переносим значения с GPU на CPU\n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n\n        # Считаем точность для отдельного батча с текстами и накапливаем значения.\n        total_eval_accuracy += flat_accuracy(logits, label_ids)\n\n    # Выводим точность для всех валидационных данных.\n    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n\n    # Считаем среднюю функцию потерь для всех батчей.\n    avg_val_loss = total_eval_loss / len(validation_dataloader)\n    # Измеряем как долго считалась валидация.\n    validation_time = format_time(time.time() - t0)\n    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    print(\"  Validation took: {:}\".format(validation_time))\n    return avg_val_loss, avg_val_accuracy, validation_time","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# В этой переменной сохраним всякую статистику по тренировке: точность, функцию цены (потерь) и время выполнения.\ntraining_stats = []\n# Переменная что бы измерить время всей тренировки.\ntotal_t0 = time.time()\n\n# Для каждой эпохи...\nfor epoch_i in range(0, epochs):\n    # Запустить одну эпоху тренировки (следующий слайд) \n    #avg_train_loss, training_time = train_step(device, model, train_dataloader, optimizer, scheduler)\n    avg_train_loss, training_time = train_step(device, model, train_dataloader, optimizer, scheduler)\n    # Запустить валидацию что бы проверить качество модели на данном этапе (следующий слайд)\n    avg_val_loss, avg_val_accuracy, validation_time = validation_step(device, model, validation_dataloader)\n\n    # Сохраняем статистику тренировки на данной эпохе.\n    training_stats.append(\n        {\n            'Epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Validation Loss': avg_val_loss,\n            'Validation Accur.': avg_val_accuracy,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        }\n    )\n\nprint(\"Training complete! Total training took {:} (hh:mm:ss)\".format(format_time(time.time() - total_t0)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm.notebook import tqdm\ndf = pd.read_csv(\"/kaggle/input/m-lab-3/test.csv\")\nsentences_test = df_test.text.values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids, attention_masks = [], []\n\n# Для всех предложений...\nfor sent in tqdm(sentences_test[:]):\n    encoded_dict = tokenizer.encode_plus(\n        sent,  # Текст для токенизации.\n        add_special_tokens=True,  # Добавляем '[CLS]' и '[SEP]'\n        max_length = 512,\n        padding = 'max_length',\n        truncation=True,\n        return_attention_mask=True,  # Возвращаем также attn. masks.\n        return_tensors='pt',  # Возвращаем в виде тензоров pytorch.\n    )\n\n    # Добавляем токенизированное предложение в список\n    input_ids.append(encoded_dict['input_ids'])\n    # И добавляем attention mask в список\n    attention_masks.append(encoded_dict['attention_mask'])\n\n# Конвертируем списки в полноценные тензоры Pytorch.\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test = TensorDataset(input_ids, attention_masks)\ntest_dataloader = DataLoader(\n        dataset_test, \n        sampler = SequentialSampler(dataset_test),\n        batch_size = batch_size,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nres = []\nfor batch in test_dataloader:\n    b_input_ids, b_input_mask = batch[0].to(device), batch[1].to(device)\n\n    with torch.no_grad():\n        # Прямой проход по нейронной сети и получение выходных значений.\n        outputs = model(input_ids=b_input_ids, token_type_ids=None,attention_mask=b_input_mask)\n        prediction = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n        res.extend(prediction)\ndf = pd.read_csv(\"/kaggle/input/miem-hse-ais-2022-lab-03/sample_submission.csv\")\ndf['positive'] = res\ndf.to_csv('answer.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}